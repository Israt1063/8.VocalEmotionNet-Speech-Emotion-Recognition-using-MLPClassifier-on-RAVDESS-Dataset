{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPE1ZpNBXMgXVF0rAMr9Tvy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Israt1063/8.VocalEmotionNet-Speech-Emotion-Recognition-using-MLPClassifier-on-RAVDESS-Dataset/blob/main/8_VocalEmotionNet_Speech_Emotion_Recognition_using_MLPClassifier_on_RAVDESS_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 🔍 Reason                                     | ✅ Explanation                                                                                           |\n",
        "| --------------------------------------------- | ------------------------------------------------------------------------------------------------------- |\n",
        "| **1. Suitable for MFCC features**             | MFCCs are **continuous numerical vectors** that are ideal input for MLPs.                               |\n",
        "| **2. Learns complex patterns**                | MLP can learn **non-linear mappings** between audio features and emotion labels.                        |\n",
        "| **3. Easy to implement with sklearn**         | You don’t need to build or tune a deep model from scratch. `sklearn`’s `MLPClassifier` makes it simple. |\n",
        "| **4. Works well on medium-sized datasets**    | RAVDESS has **1440 samples**, which is small for deep learning but sufficient for an MLP.               |\n",
        "| **5. Handles multi-class classification**     | RAVDESS has 8 emotion classes – MLP supports **multi-class softmax** out of the box.                    |\n",
        "| **6. No need for manual feature engineering** | Once MFCCs are extracted, MLP can learn directly from them without extra rules.                         |\n",
        "\n"
      ],
      "metadata": {
        "id": "gpAg542MmANw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uL97f1xAmALL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import requests\n",
        "import zipfile\n"
      ],
      "metadata": {
        "id": "ccyeXv9nVrmO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Download RAVDESS dataset zip file from a public URL (Direct link)\n",
        "dataset_url = \"https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip?download=1\"\n",
        "dataset_path = \"ravdess.zip\"\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "\n",
        "    print(\"Downloading RAVDESS dataset...\")\n",
        "    r = requests.get(dataset_url)\n",
        "    with open(dataset_path, \"wb\") as f:\n",
        "        f.write(r.content)\n",
        "    print(\"Download completed.\")\n",
        "else:\n",
        "    print(\"Dataset already downloaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL9w_Gw4YCDB",
        "outputId": "6a23deb8-dcc3-4d76-d6d8-12f6d9258177"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading RAVDESS dataset...\n",
            "Download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Extract dataset zip if not extracted\n",
        "extract_folder = \"Audio_Speech_Actors_01-24\"\n",
        "if not os.path.exists(extract_folder):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "    print(\"Extraction done.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2jH4jx9YLLZ",
        "outputId": "f3547f15-76e4-42e5-da85-de6a57d61ca8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "Extraction done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files and folders in current working directory\n",
        "print(\"Current directory contents:\")\n",
        "print(os.listdir())\n",
        "\n",
        "# Check inside your extracted folder (if it exists)\n",
        "if 'Audio_Speech_Actors_01-24' in os.listdir():\n",
        "    print(\"Extracted folder found: Audio_Speech_Actors_01-24\")\n",
        "else:\n",
        "    # List folders that start with \"Audio\"\n",
        "    print(\"Folders starting with 'Audio':\")\n",
        "    for item in os.listdir():\n",
        "        if item.startswith('Audio'):\n",
        "            print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMx3VC7mYvhD",
        "outputId": "4f41ac8c-5a03-4a36-de91-0533ca0b0d6e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory contents:\n",
            "['.config', 'ravdess.zip', 'Actor_09', 'Actor_22', 'Actor_10', 'Actor_15', 'Actor_17', 'Actor_11', 'Actor_21', 'Actor_02', 'Actor_24', 'Actor_14', 'Actor_18', 'Actor_07', 'Actor_20', 'Actor_04', 'data', 'Actor_01', 'Actor_05', 'Actor_12', 'Actor_13', 'Actor_16', 'Actor_19', 'Actor_06', 'Actor_23', 'Actor_08', 'Actor_03', 'sample_data']\n",
            "Folders starting with 'Audio':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall librosa -y\n",
        "!pip install librosa==0.9.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "cMau3h1fca_D",
        "outputId": "ef61671c-8b53-4b8d-d860-e0ac2c7bf64d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: librosa 0.11.0\n",
            "Uninstalling librosa-0.11.0:\n",
            "  Successfully uninstalled librosa-0.11.0\n",
            "Collecting librosa==0.9.2\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2) (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2) (4.4.2)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.9.2)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.2) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.45.1->librosa==0.9.2) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.9.2) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.9.2) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.2) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.2->librosa==0.9.2) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (2025.4.26)\n",
            "Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: resampy, librosa\n",
            "Successfully installed librosa-0.9.2 resampy-0.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "librosa"
                ]
              },
              "id": "8b74f64c980e46d9a134f675814cee27"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = \".\"  # or \"data\" if you moved actors inside data\n",
        "actor_dirs = [d for d in os.listdir(base_path) if d.startswith(\"Actor_\")]\n",
        "print(\"Actor folders found:\", actor_dirs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn9fvyBUctdS",
        "outputId": "fe1ea61f-908e-4242-a309-51f71d1f6a30"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actor folders found: ['Actor_09', 'Actor_22', 'Actor_10', 'Actor_15', 'Actor_17', 'Actor_11', 'Actor_21', 'Actor_02', 'Actor_24', 'Actor_14', 'Actor_18', 'Actor_07', 'Actor_20', 'Actor_04', 'Actor_01', 'Actor_05', 'Actor_12', 'Actor_13', 'Actor_16', 'Actor_19', 'Actor_06', 'Actor_23', 'Actor_08', 'Actor_03']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "wav_files = glob.glob(os.path.join(base_path, \"Actor_*\", \"*.wav\"))\n",
        "print(\"Total .wav files:\", len(wav_files))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hak6a4Ducw8v",
        "outputId": "e04fed65-174c-4e00-f729-4809baacb2ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total .wav files: 1440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_map = {\n",
        "    '01': 'neutral',\n",
        "    '02': 'calm',\n",
        "    '03': 'happy',\n",
        "    '04': 'sad',\n",
        "    '05': 'angry',\n",
        "    '06': 'fearful',\n",
        "    '07': 'disgust',\n",
        "    '08': 'surprised'\n",
        "}\n"
      ],
      "metadata": {
        "id": "S_vV_Mkjc0HV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "emotion_counts = defaultdict(int)\n",
        "for file in wav_files:\n",
        "    emotion_code = os.path.basename(file).split(\"-\")[2]\n",
        "    emotion = emotion_map.get(emotion_code, \"unknown\")\n",
        "    emotion_counts[emotion] += 1\n",
        "\n",
        "print(dict(emotion_counts))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6hLcB0mc3Jm",
        "outputId": "55e62557-21e6-48a4-8157-364cb6ca168c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sad': 192, 'surprised': 192, 'happy': 192, 'fearful': 192, 'disgust': 192, 'angry': 192, 'neutral': 96, 'calm': 192}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "corrupted = []\n",
        "for file in wav_files:\n",
        "    try:\n",
        "        y, sr = librosa.load(file)\n",
        "        if y.shape[0] == 0:\n",
        "            corrupted.append(file)\n",
        "    except Exception:\n",
        "        corrupted.append(file)\n",
        "\n",
        "print(f\"Corrupted files: {len(corrupted)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v07ozubvc61Z",
        "outputId": "4a6f3081-4439-4783-9039-9edf102e03ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrupted files: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def extract_features(file_path):\n",
        "    try:\n",
        "        audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
        "        mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
        "        return mfccs_scaled\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {file_path}, {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "HS3FOX2CeDUp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = [], []\n",
        "for file in wav_files:\n",
        "    data = extract_features(file)\n",
        "    if data is not None:\n",
        "        features.append(data)\n",
        "        emotion_code = os.path.basename(file).split(\"-\")[2]\n",
        "        labels.append(emotion_map[emotion_code])\n",
        "\n",
        "X = np.array(features)\n",
        "y = np.array(labels)\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9eI6VXPeHIQ",
        "outputId": "d1250e4f-2f6f-4331-f580-333fd3747f86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (1440, 40)\n",
            "Labels shape: (1440,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwd_Cs5keqJL",
        "outputId": "3f0ac3d8-5ce3-455d-d33d-b366d5f5851d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6284722222222222\n"
          ]
        }
      ]
    }
  ]
}